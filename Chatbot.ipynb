{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8690b92f",
   "metadata": {},
   "source": [
    "# Conversations with LangChain Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c85a8",
   "metadata": {},
   "source": [
    "> Ming Zhao\n",
    "> \n",
    "> Dec, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c44e9",
   "metadata": {},
   "source": [
    "The goal of this project is to develop a chatbot capable of engaging in interactive conversations, remembering previous interactions, and generating responses based on the referenced documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34aa0a6",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "1. Document Loading    \n",
    "2. Document Splitting      \n",
    "3. Embedding   \n",
    "4. Retrieval\n",
    "5. Question Answering\n",
    "6. Conversational Chat\n",
    "7. Create A Chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba36fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain\n",
    "# ! pip install pypdf\n",
    "# ! pip install chromadb\n",
    "# ! pip install -U langchain-openai\n",
    "# ! pip install lark\n",
    "# ! pip install \"langchain[docarray]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aecafbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49f52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ada2f",
   "metadata": {},
   "source": [
    "## 1. Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f1d6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documets\n",
    "# loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "# pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec45191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PDF\n",
    "loaders = [\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture03.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture04.pdf\")\n",
    "]\n",
    "pages = []\n",
    "for loader in loaders:\n",
    "    pages.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ced6475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178575dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is ju st spend a little time going over the logistics \n",
      "of the class, and then we'll start to  talk a bit about machine learning.  \n",
      "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \n",
      "I personally work in machine learning, and I' ve worked on it for about 15 years now, and \n",
      "I actually think that machine learning i\n"
     ]
    }
   ],
   "source": [
    "print(pages[0].page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b68f96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'MachineLearning-Lecture01.pdf', 'page': 20}\n",
      "{'source': 'MachineLearning-Lecture01.pdf', 'page': 21}\n",
      "{'source': 'MachineLearning-Lecture02.pdf', 'page': 0}\n",
      "{'source': 'MachineLearning-Lecture02.pdf', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "for page in pages[20:24]:\n",
    "    print(page.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da67fe",
   "metadata": {},
   "source": [
    "## 2. Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9479f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=150)\n",
    "\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb725c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32daa44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='[End of Audio] \\nDuration: 76 minutes', metadata={'source': 'MachineLearning-Lecture04.pdf', 'page': 19})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[281]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b23562",
   "metadata": {},
   "source": [
    "## 3. Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c65c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfa35c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define embedding\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e31f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store vectors\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "622b62e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47cb4c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup that's sort of a forum for people in  the class to get to  know each other and \n",
      "have whatever discussions you want to ha ve amongst yourselves. So the class newsgroup \n",
      "will not be monitored by the TAs and me. But this is a place for you to form study groups \n",
      "or find project partners or discuss homework problems and so on, and it's not monitored \n",
      "by the TAs and me. So feel free to ta lk trash about this class there.  \n",
      "If you want to contact the teaching staff, pl ease use the email addr\n",
      "--------------------------------------------------\n",
      "sort of just fishing around for ideas or l ooking for ideas of projects to do, please, be \n",
      "strongly encouraged to come to  my office hours on Friday mornings, or go to any of the \n",
      "TAâ€™s office hours to tell us a bout your project ideas, and we can help brainstorm with \n",
      "you.  \n",
      "I also have a list of project ideas that I so rt of collected from my colleagues and from \n",
      "various senior PhD students working with me  or with other professors. And so if you \n",
      "want to hear about some of those ideas in  topi\n"
     ]
    }
   ],
   "source": [
    "question1 = \"is there an email i can ask for help\"\n",
    "ans1 = vectordb.similarity_search(question1, k=3) # len(ans)=3\n",
    "print(ans1[0].page_content[:500])\n",
    "print(\"-\"*50)\n",
    "print(ans1[1].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eb256db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine l earning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your \n",
      "machine learning class. I learned so much from\n",
      "--------------------------------------------------\n",
      "those homeworks will be done in either MATLA B or in Octave, which is sort of â€” I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to u\n"
     ]
    }
   ],
   "source": [
    "question2 = \"what did they say about matlab?\"\n",
    "ans2 = vectordb.similarity_search(question2, k=3)\n",
    "print(ans2[0].page_content[:500])\n",
    "print(\"-\"*50)\n",
    "print(ans2[1].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fdbe302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture03  \n",
      "Instructor (Andrew Ng) :Okay. Good morning and welcome b ack to the third lecture of \n",
      "this class. So hereâ€™s what I want to do t oday, and some of the topics I do today may seem \n",
      "a little bit like Iâ€™m jumping, sort  of, from topic to topic, but hereâ€™s, sort of, the outline for \n",
      "today and the illogical flow of ideas. In the last lecture, we  talked about linear regression \n",
      "and today I want to talk about sort of an  adaptation of that called locally weighted \n",
      "regression.\n",
      "--------------------------------------------------\n",
      "Instructor (Andrew Ng) :All right, so who thought driving could be that dramatic, right? \n",
      "Switch back to the chalkboard, please. I s hould say, this work was done about 15 years \n",
      "ago and autonomous driving has come a long way. So many of you will have heard of the \n",
      "DARPA Grand Challenge, where one of my colleagues, Sebastian Thrun, the winning \n",
      "team's drive a car across a desert by itself.  \n",
      "So Alvin was, I think, absolutely amazing wo rk for its time, but autonomous driving has \n",
      "obviously come \n"
     ]
    }
   ],
   "source": [
    "question3 = \"what did they say about regression in the third lecture?\"\n",
    "ans3 = vectordb.similarity_search(question3, k=5)\n",
    "print(ans3[0].page_content[:500])\n",
    "print(\"-\"*50)\n",
    "print(ans3[1].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f14034",
   "metadata": {},
   "source": [
    "## 4. Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5500e2",
   "metadata": {},
   "source": [
    "**Addressing Diversity: Maximum Marginal Relevance**\n",
    "\n",
    "`Maximum Marginal Relevance` strives to achieve both *relevance* to the query and *diversity* among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f52d1364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine l earning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your \n",
      "machine learning class. I learned so much from\n",
      "--------------------------------------------------\n",
      "those homeworks will be done in either MATLA B or in Octave, which is sort of â€” I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to u\n"
     ]
    }
   ],
   "source": [
    "ans2_mmr = vectordb.max_marginal_relevance_search(question2, k=3)\n",
    "print(ans2_mmr[0].page_content[:500])\n",
    "print(\"-\"*50)\n",
    "print(ans2_mmr[1].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a8e36",
   "metadata": {},
   "source": [
    "**Addressing Specificity: Working with Metadata**\n",
    "\n",
    "`Metadata` provides context for each embedded chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96d3ba73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': 'MachineLearning-Lecture03.pdf'}\n",
      "{'page': 13, 'source': 'MachineLearning-Lecture03.pdf'}\n",
      "{'page': 10, 'source': 'MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "ans3_meta = vectordb.similarity_search(\n",
    "    question3, k=3,\n",
    "    filter={\"source\":\"MachineLearning-Lecture03.pdf\"})\n",
    "\n",
    "for d in ans3_meta:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd46748",
   "metadata": {},
   "source": [
    "**Addressing Specificity: Working with Metadata Using Self-query Retriever**\n",
    "\n",
    "`SelfQueryRetriever` uses an LLM to extract:\n",
    " \n",
    "1. The `query` string to use for vector search\n",
    "2. A metadata filter to pass in\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "030a9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of  \\\n",
    "                    `MachineLearning-Lecture01.pdf`,  \\\n",
    "                    `MachineLearning-Lecture02.pdf`,  \\\n",
    "                    `MachineLearning-Lecture03.pdf`,  \\\n",
    "                    `MachineLearning-Lecture04.pdf`\", \n",
    "        type=\"string\"),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\")]\n",
    "\n",
    "document_content_description = \"Lecture notes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6ba4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', \n",
    "             temperature=0,\n",
    "             openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c32182ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans3_self = retriever.get_relevant_documents(question3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "076d38bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 2, 'source': 'MachineLearning-Lecture03.pdf'}\n",
      "{'page': 1, 'source': 'MachineLearning-Lecture03.pdf'}\n",
      "{'page': 0, 'source': 'MachineLearning-Lecture03.pdf'}\n",
      "{'page': 10, 'source': 'MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in ans3_self:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6cb882",
   "metadata": {},
   "source": [
    "**Additional Tricks: Compression**\n",
    "\n",
    "Information most relevant to a query may be buried in a document with a lot of irrelevant text.\n",
    "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "Contextual compression is meant to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5655471",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4955a596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 8, 'source': 'MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'MachineLearning-Lecture01.pdf'}\n",
      "{'page': 9, 'source': 'MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "ans2_comp = compression_retriever.get_relevant_documents(question2)\n",
    "\n",
    "for d in ans2_comp:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d225f2dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='- \"So actually I, well, so yeah, just a side comment for those of you that haven\\'t seen MATLAB before I guess\"\\n- \"So one day, he was in his office, and an old student of his from, lik e, ten years ago came into his office and he said, \"Oh, professo r, professor, thank you so much for your machine learning class.\"\\n- \"I learned so much from it. There\\'s this stuff that I learned in your class, and I now use every day. And it\\'s help ed me make lots of money, and here\\'s a picture of my big house.\"\\n- \"So my friend was very excited. He said, \"W ow. That\\'s great. I\\'m glad to hear this machine learning stuff was actually useful. So what was it that you learned? Was it logistic regression? Was it the PCA? Was it the data ne tworks? What was it that you learned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"' metadata={'page': 8, 'source': 'MachineLearning-Lecture01.pdf'}\n",
      "--------------------------------------------------\n",
      "page_content='MATLAB, Octave, free version of MATLAB, programming language, write codes using matrices, numerical routines, move data around, plot data, easy to learn tool, implementing learning algorithms, work on your own home computer, MATLAB license, software package called Octave, download for free off the Internet, fewer features than MATLAB, free, work for just about' metadata={'page': 8, 'source': 'MachineLearning-Lecture01.pdf'}\n",
      "--------------------------------------------------\n",
      "page_content='- \"all the homeworks can be done in MATLAB or Octave\"\\n- \"the program prerequisites is more the ability to understand big?O notation and knowledge of what a data structure, like a linked list or a queue or binary treatments\"\\n- \"let\\'s see\"\\n- \"the goal as being to do a cool piece of machine learning work that will let you experience\"' metadata={'page': 9, 'source': 'MachineLearning-Lecture01.pdf'}\n",
      "--------------------------------------------------\n",
      "page_content='\"Oh, it was the MATLAB.\"' metadata={'page': 8, 'source': 'MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(ans2_comp[0])\n",
    "print(\"-\"*50)\n",
    "print(ans2_comp[1])\n",
    "print(\"-\"*50)\n",
    "print(ans2_comp[2])\n",
    "print(\"-\"*50)\n",
    "print(ans2_comp[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8cc38",
   "metadata": {},
   "source": [
    "- Combining Various Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dc5d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3862ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 8, 'source': 'MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'MachineLearning-Lecture01.pdf'}\n",
      "{'page': 7, 'source': 'MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "ans2_comb = compression_retriever.get_relevant_documents(question2)\n",
    "\n",
    "for d in ans2_comb:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "677aa4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='- \"So actually I, well, so yeah, just a side comment for those of you that haven\\'t seen MATLAB before I guess\"\\n- \"So one day, he was in his office, and an old student of his from, lik e, ten years ago came into his office and he said, \"Oh, professo r, professor, thank you so much for your machine learning class.\"\\n- \"I learned so much from it. There\\'s this stuff that I learned in your class, and I now use every day. And it\\'s help ed me make lots of money, and here\\'s a picture of my big house.\"\\n- \"So my friend was very excited. He said, \"W ow. That\\'s great. I\\'m glad to hear this machine learning stuff was actually useful. So what was it that you learned? Was it logistic regression? Was it the PCA? Was it the data ne tworks? What was it that you learned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"' metadata={'page': 8, 'source': 'MachineLearning-Lecture01.pdf'}\n",
      "--------------------------------------------------\n",
      "page_content='MATLAB, Octave, free version of MATLAB, programming language, write codes using matrices, numerical routines, move data around, plot data, easy to learn tool, implementing learning algorithms, work on your own home computer, MATLAB license, software package called Octave, download for free off the Internet, fewer features than MATLAB, free, work for just about' metadata={'page': 8, 'source': 'MachineLearning-Lecture01.pdf'}\n",
      "--------------------------------------------------\n",
      "page_content='- \"all the homeworks can be done in MATLAB or Octave\"\\n- \"the program prerequisites is more the ability to understand big?O notation and knowledge of what a data structure, like a linked list or a queue or binary treatments\"\\n- \"let\\'s see\"\\n- \"the goal as being to do a cool piece of machine learning work that will let you experience\"' metadata={'page': 9, 'source': 'MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(ans2_comp[0])\n",
    "print(\"-\"*50)\n",
    "print(ans2_comp[1])\n",
    "print(\"-\"*50)\n",
    "print(ans2_comp[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a91937",
   "metadata": {},
   "source": [
    "**Other Types of Retrieval**\n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd944029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f98832e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PDF\n",
    "# loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "# pages = loader.load()\n",
    "# all_page_text=[p.page_content for p in pages]\n",
    "# joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# split\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "# splits = text_splitter.split_text(joined_page_text)\n",
    "\n",
    "# Retrieve\n",
    "# svm_retriever = SVMRetriever.from_texts(splits,embeddings)\n",
    "# tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf41fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"What are major topics for this class?\"\n",
    "# docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "# docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aee1e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"What are major topics for this class?\"\n",
    "# docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "# docs_tfidf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ae35b",
   "metadata": {},
   "source": [
    "## 5. Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef08c54",
   "metadata": {},
   "source": [
    "**RetrievalQA Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce63f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", \n",
    "                 temperature=0,\n",
    "                 openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb67cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The major topics for this class are machine learning and its extensions. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "result = qa_chain.invoke(question)\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea74c596",
   "metadata": {},
   "source": [
    "**Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfa978c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "              If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "              Use three sentences maximum. Keep the answer as concise as possible. \n",
    "              Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "698f13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "185860f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, probability is a topic in this class. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa_chain.invoke(question)\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d866992b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"of this class will not be very program ming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octa ve. I'll say a bit more about that later.  \\nI also assume familiarity with basic proba bility and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what ra ndom variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basi c linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51,\", metadata={'page': 4, 'source': 'MachineLearning-Lecture01.pdf'})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"source_documents\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309009d",
   "metadata": {},
   "source": [
    "**RetrievalQA Chain Types**\n",
    "\n",
    "- map-reduce\n",
    "- refine\n",
    "- map-rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84d875cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b22a34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, probability is a class topic.\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain_mr.invoke(question)\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54bba670",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5774dd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, probability is a class topic.\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain_mr.invoke(question)\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fb825",
   "metadata": {},
   "source": [
    "### RetrievalQA Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26faa822",
   "metadata": {},
   "source": [
    "#### QA fails to preserve conversational history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b1c36c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, probability is a topic in this class. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa_chain.invoke(question)\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2af7477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prerequisites are needed because the class assumes that students have basic knowledge of computer science, computer skills, and programming skills. This knowledge is necessary to understand and apply the concepts taught in the class. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "result = qa_chain.invoke(question)\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb77f6",
   "metadata": {},
   "source": [
    "## 6. Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7613f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", \n",
    "                 temperature=0,\n",
    "                 openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bdc555b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54b7b6",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da1ba0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    input_key='question', \n",
    "    output_key='answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fec0b6",
   "metadata": {},
   "source": [
    "### Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88d36dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectordb.as_retriever()\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    return_generated_question=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9f3522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, probability is a topic covered in the class. The instructor assumes familiarity with basic probability and statistics. Additionally, there is a discussion section dedicated to reviewing probability for those who need a refresher.\n"
     ]
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9acdea6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Familiarity with basic probability and statistics is assumed because these concepts are fundamental to understanding and applying machine learning algorithms. Probability and statistics provide the foundation for understanding uncertainty, making predictions, and evaluating the performance of models. \n",
      "\n",
      "The discussion section dedicated to reviewing probability is offered for those who may not have a strong background in probability and statistics or who may need a refresher. This is to ensure that all students have the necessary prerequisite knowledge to fully understand and engage with the material covered in the class. The review session aims to provide a solid foundation in probability concepts before diving into more advanced topics in machine learning.\n"
     ]
    }
   ],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "result = qa({\"question\": question})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a0e316",
   "metadata": {},
   "source": [
    "## 7. Create A Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc1be892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(files, chain_type=\"map_reduce\", temperature=0, k=2):\n",
    "    '''\n",
    "    files: a list of file names or a file name\n",
    "    chain_type: map_reduce, refine, map_rerank\n",
    "    temperature: this parameter controls the creativity of the text generated by the OpenAI API. \n",
    "                 A higher temperature will produce more creative text, \n",
    "                 while a lower temperature will produce more predictable text.\n",
    "    '''\n",
    "    \n",
    "    # load documents\n",
    "    loaders = []\n",
    "    for file in files:\n",
    "        loaders.append(PyPDFLoader(file))\n",
    "    pages = []\n",
    "    for loader in loaders:\n",
    "        pages.extend(loader.load())\n",
    "        \n",
    "    # split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "    \n",
    "    # define embedding\n",
    "    OPENAI_API_KEY = \"OPENAI_API_KEY\"\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # store vector in memery\n",
    "    db = Chroma.from_documents(documents=docs, embedding=embeddings)\n",
    "    ###db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    \n",
    "    # define retriever\n",
    "    retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=vectordb.as_retriever(search_type = \"mmr\"))\n",
    "    ###retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2} #k: top k relevant documents which are retrieved)\n",
    "    \n",
    "    # define memory\n",
    "    memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True, \n",
    "            input_key='question', \n",
    "            output_key='answer')\n",
    "    \n",
    "    # deine LLM\n",
    "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\", temperature=temperature)\n",
    "    \n",
    "    # create a chatbot chain\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "            llm,  \n",
    "            chain_type=chain_type, \n",
    "            retriever=retriever, \n",
    "            memory=memory,\n",
    "            return_source_documents=True,\n",
    "            return_generated_question=True)\n",
    "        \n",
    "    return qa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9f1eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = load_db([\"MachineLearning-Lecture01.pdf\", \"MachineLearning-Lecture02.pdf\",\n",
    "              \"MachineLearning-Lecture03.pdf\", \"MachineLearning-Lecture04.pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afe14d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is this class useful?\"\n",
    "result = qa.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce86c5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, based on the given information, the class is described as being useful for doing many things and the things learned in the class will be useful no matter what the student ends up doing later in life.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])\n",
    "# print(result['generated_question'])\n",
    "# print(result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278adac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b764b77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b80a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab27d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
